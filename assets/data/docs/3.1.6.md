# Erfolgskriterium 3.1.6 Aussprache

**Stufe AAA**

**Ziel**  
Das Ziel des WCAG-Erfolgskriteriums **3.1.6 „Aussprache“ (Level AAA)** ist es, Nutzer:innen die richtige Aussprache von Wörtern zugänglich zu machen, wenn deren Bedeutung im Kontext ohne Aussprache nicht eindeutig ist.  
Das betrifft Wörter, die gleich geschrieben, aber unterschiedlich ausgesprochen und unterschiedlich gemeint sind (z. B. englische Heteronyme), sowie Sprachen mit Zeichen, die mehrere mögliche Lesungen haben (z. B. japanische Kanji).  
Ein Mechanismus – visuell oder programmatisch – muss bereitstehen, um die korrekte Aussprache zu erkennen oder abzurufen.

**Absicht**  
Die Absicht dieses Kriteriums ist es, Personen mit Blindheit, Sehbehinderung oder Leseschwierigkeiten dabei zu unterstützen, Inhalte korrekt zu verstehen, wenn die Bedeutung eines Wortes von seiner Aussprache abhängt.

Viele Wörter können erst durch ihre Aussprache eindeutig eingeordnet werden. Während sehende Menschen oft aus dem Satzbau oder Betonungsmustern Rückschlüsse ziehen, haben Nutzer:innen, die auf Screenreader oder synthetische Sprache angewiesen sind, ein zusätzliches Problem:  
Wird das Wort falsch ausgesprochen, wird der gesamte Satz unverständlich oder verwirrend.

Beispiele für solche Problemfälle:

-   **Heteronyme (gleich geschrieben, unterschiedlich ausgesprochen und gemeint):**  
    Englisch: _desert_ (verlassen) vs. _desert_ (Wüste).  
    Wenn der Satz das nicht eindeutig macht, ist eine Aussprachehilfe nötig.

-   **Zeichensprachen mit mehreren Lesungen:**  
    Im Japanischen können Kanji mehrere Aussprachen haben.  
    Ohne Ruby-Anmerkungen oder Kana-Angaben liest ein Screenreader sie oft falsch vor.

Die Bereitstellung eines Mechanismus – z. B. Ruby-Elemente, Klangdateien oder Glossareinträge – stellt sicher, dass Nutzer:innen solche Wörter korrekt verstehen können.

**Vorteile (Wirkung)**

-   **Besseres Verständnis für Personen mit Leseschwierigkeiten:**  
    Wenn die Bedeutung nur durch die Aussprache klar wird, verhindert eine Aussprachehilfe Missverständnisse.

-   **Unterstützung für Nutzer:innen von Screenreadern:**  
    Synthetische Stimmen können Wörter ohne zusätzliche Hinweise falsch aussprechen.  
    Ausspracheangaben schaffen Klarheit und entlasten kognitiv.

-   **Hilfe für Menschen, die Kontext schwer erkennen:**  
    Einige Nutzer:innen können Bedeutungen nicht zuverlässig aus dem Satzbau ableiten.  
    Die Aussprache gibt ihnen eine eindeutige Orientierung.

-   **Barrierefreie Darstellung linguistisch komplexer Inhalte:**  
    Besonders wichtig für Inhalte in Sprachen mit Mehrdeutigkeiten oder variablen Schriftzeichen (z. B. Japanisch, Chinesisch).

**Beispiele für Mechanismen**

-   **Aussprachehilfe direkt im Text:**  
    Japanische Webseiten schreiben Kana in Klammern neben Kanji, um die Lesung zu zeigen. Screenreader lesen beide Versionen, was die Bedeutung deutlich macht.

-   **Ruby-Elemente in HTML:**  
    Kleine Zeichen über dem Wort (z. B. `<ruby>Kanji<rt>Lesung</rt></ruby>`) zeigen die richtige Aussprache.  
    Dieses Verfahren wird besonders in Ostasiatischen Sprachen genutzt.

-   **Verlinkte Audio-Beispiele:**  
    Einzelne unklare Wörter sind mit Sounddateien verlinkt, damit Nutzer:innen die richtige Aussprache anhören können.

-   **Glossare mit Ausspracheangabe:**  
    Ein Glossar bietet nicht nur Definitionen, sondern auch Lautschrift oder Tonbeispiele.  
    Wörter im Text sind zu den entsprechenden Glossareinträgen verlinkt.

-   **Aussprachehinweise bei fremdsprachigen Zitaten:**  
    Z. B. japanische Webseiten, die chinesische oder koreanische Zeichen wiedergeben, ergänzen die jeweiligen Sprach-spezifischen Lesungen.
